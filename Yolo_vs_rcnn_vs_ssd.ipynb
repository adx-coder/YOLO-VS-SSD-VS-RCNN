{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import kagglehub\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, ssd300_vgg16\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "# Create a results folder in Colab\n",
    "RESULTS_FOLDER = '/content/object_detection_results'\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 1: Download the 'indoor-object-detection' dataset from Kaggle\n",
    "def download_kaggle_dataset():\n",
    "    print(\"Downloading the 'indoor-object-detection' dataset from Kaggle...\")\n",
    "    path = kagglehub.dataset_download(\"thepbordin/indoor-object-detection\")\n",
    "    print(\"Dataset downloaded successfully.\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "    return path\n",
    "\n",
    "# Step 2: Image Preprocessing (resize and normalize)\n",
    "def preprocess_image(image, size=(640, 640)):\n",
    "    img_resized = cv2.resize(image, size)\n",
    "    img_normalized = img_resized / 255.0\n",
    "    img_uint8 = (img_normalized * 255).astype('uint8')\n",
    "    return img_uint8\n",
    "\n",
    "# Function to save image in the results folder\n",
    "def save_image(img, filename):\n",
    "    full_path = os.path.join(RESULTS_FOLDER, filename)\n",
    "    cv2.imwrite(full_path, img)\n",
    "    return full_path\n",
    "\n",
    "# Step 3: Process a single image with YOLOv8\n",
    "def process_image_yolov8(image_path, conf_threshold=0.3):\n",
    "    print(f\"Processing image with YOLOv8: {image_path}\")\n",
    "    model = YOLO('yolov8x.pt').to(device)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img_preprocessed = preprocess_image(img)\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = model(img_preprocessed, conf=conf_threshold, iou=0.5)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    img_draw = img.copy()\n",
    "    detection_counts = {}\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            label = result.names[int(box.cls)]\n",
    "            detection_counts[label] = detection_counts.get(label, 0) + 1\n",
    "            cv2.rectangle(img_draw, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label_conf = f\"{label} {conf:.2f}\"\n",
    "            cv2.putText(img_draw, label_conf, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    processed_filename = 'processed_yolov8_' + os.path.basename(image_path)\n",
    "    saved_path = save_image(img_draw, processed_filename)\n",
    "    return saved_path, detection_counts, inference_time\n",
    "\n",
    "# Step 4: Process a single image with Faster R-CNN\n",
    "def process_image_faster_rcnn(image_path):\n",
    "    print(f\"Processing image with Faster R-CNN: {image_path}\")\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img_preprocessed = preprocess_image(img)\n",
    "    img_rgb = cv2.cvtColor(img_preprocessed, cv2.COLOR_BGR2RGB)\n",
    "    img_tensor = F.to_tensor(img_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    img_draw = img.copy()\n",
    "    detection_counts = {}\n",
    "\n",
    "    for box, label, score in zip(predictions[0]['boxes'], predictions[0]['labels'], predictions[0]['scores']):\n",
    "        if score >= 0.3:\n",
    "            x1, y1, x2, y2 = map(int, box.cpu().tolist())\n",
    "            label_name = f\"Label {label.item()}\"\n",
    "            detection_counts[label_name] = detection_counts.get(label_name, 0) + 1\n",
    "            cv2.rectangle(img_draw, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            label_conf = f\"{label_name} {score:.2f}\"\n",
    "            cv2.putText(img_draw, label_conf, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    processed_filename = 'processed_fasterrcnn_' + os.path.basename(image_path)\n",
    "    saved_path = save_image(img_draw, processed_filename)\n",
    "    return saved_path, detection_counts, inference_time\n",
    "\n",
    "# Step 5: Process a single image with SSD (Single Shot MultiBox Detector)\n",
    "def process_image_ssd(image_path, conf_threshold=0.3):\n",
    "    print(f\"Processing image with SSD: {image_path}\")\n",
    "    model = ssd300_vgg16(pretrained=True).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img_preprocessed = preprocess_image(img)\n",
    "    img_rgb = cv2.cvtColor(img_preprocessed, cv2.COLOR_BGR2RGB)\n",
    "    img_tensor = F.to_tensor(img_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    img_draw = img.copy()\n",
    "    detection_counts = {}\n",
    "\n",
    "    for box, score in zip(predictions[0]['boxes'], predictions[0]['scores']):\n",
    "        if score >= conf_threshold:\n",
    "            x1, y1, x2, y2 = map(int, box.cpu().tolist())\n",
    "            detection_counts[\"SSD Object\"] = detection_counts.get(\"SSD Object\", 0) + 1\n",
    "            cv2.rectangle(img_draw, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            label_conf = f\"Object {score:.2f}\"\n",
    "            cv2.putText(img_draw, label_conf, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    processed_filename = 'processed_ssd_' + os.path.basename(image_path)\n",
    "    saved_path = save_image(img_draw, processed_filename)\n",
    "    return saved_path, detection_counts, inference_time\n",
    "\n",
    "# Function to display and save comparison images\n",
    "def display_images(original, yolo, rcnn, ssd, filename):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(cv2.cvtColor(yolo, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('YOLOv8 Detection')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(cv2.cvtColor(rcnn, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Faster R-CNN Detection')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(cv2.cvtColor(ssd, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('SSD Detection')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(RESULTS_FOLDER, f'comparison_plot_{filename}.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "# Function to save checkpoint\n",
    "def save_checkpoint(dataset_dir, processed_files, results_list):\n",
    "    checkpoint = {\n",
    "        'dataset_dir': dataset_dir,\n",
    "        'processed_files': processed_files,\n",
    "        'results_list': results_list\n",
    "    }\n",
    "    checkpoint_path = os.path.join(RESULTS_FOLDER, 'checkpoint.json')\n",
    "    with open(checkpoint_path, 'w') as f:\n",
    "        json.dump(checkpoint, f)\n",
    "\n",
    "# Function to load checkpoint\n",
    "def load_checkpoint():\n",
    "    checkpoint_path = os.path.join(RESULTS_FOLDER, 'checkpoint.json')\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        with open(checkpoint_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "# Step 6: Run object detection on images from the dataset with checkpointing and batching\n",
    "def run_object_detection(dataset_dir, max_images=600, batch_size=10):\n",
    "    checkpoint = load_checkpoint()\n",
    "    if checkpoint and checkpoint['dataset_dir'] == dataset_dir:\n",
    "        processed_files = set(checkpoint['processed_files'])\n",
    "        results_list = checkpoint['results_list']\n",
    "        print(f\"Resuming from checkpoint. {len(processed_files)} images already processed.\")\n",
    "    else:\n",
    "        processed_files = set()\n",
    "        results_list = []\n",
    "\n",
    "    image_files = [f for f in os.listdir(dataset_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    image_files = [f for f in image_files if f not in processed_files][:max_images]\n",
    "\n",
    "    for i in tqdm(range(0, len(image_files), batch_size), desc=\"Processing Batches\", unit=\"batch\"):\n",
    "        batch = image_files[i:i+batch_size]\n",
    "        for filename in batch:\n",
    "            image_path = os.path.join(dataset_dir, filename)\n",
    "            original_image = cv2.imread(image_path)\n",
    "\n",
    "            # YOLOv8\n",
    "            processed_filename_yolo, detection_counts_yolo, yolo_time = process_image_yolov8(image_path)\n",
    "            yolo_image = cv2.imread(processed_filename_yolo)\n",
    "\n",
    "            # Faster R-CNN\n",
    "            processed_filename_rcnn, detection_counts_rcnn, rcnn_time = process_image_faster_rcnn(image_path)\n",
    "            rcnn_image = cv2.imread(processed_filename_rcnn)\n",
    "\n",
    "            # SSD\n",
    "            processed_filename_ssd, detection_counts_ssd, ssd_time = process_image_ssd(image_path)\n",
    "            ssd_image = cv2.imread(processed_filename_ssd)\n",
    "\n",
    "            # Display and save the comparison plot\n",
    "            display_images(original_image, yolo_image, rcnn_image, ssd_image, filename)\n",
    "\n",
    "            results_list.append({\n",
    "                \"Image\": filename,\n",
    "                \"YOLOv8 Detections\": detection_counts_yolo,\n",
    "                \"YOLOv8 Time (s)\": yolo_time,\n",
    "                \"Faster R-CNN Detections\": detection_counts_rcnn,\n",
    "                \"Faster R-CNN Time (s)\": rcnn_time,\n",
    "                \"SSD Detections\": detection_counts_ssd,\n",
    "                \"SSD Time (s)\": ssd_time\n",
    "            })\n",
    "\n",
    "            processed_files.add(filename)\n",
    "\n",
    "        # Save checkpoint after each batch\n",
    "        save_checkpoint(dataset_dir, list(processed_files), results_list)\n",
    "\n",
    "        # Save partial results to CSV in the results folder\n",
    "        partial_csv_path = os.path.join(RESULTS_FOLDER, 'comparative_analysis_partial.csv')\n",
    "        df_results = pd.DataFrame(results_list)\n",
    "        df_results.to_csv(partial_csv_path, index=False)\n",
    "        print(f\"Partial results saved. Processed {len(processed_files)} images so far.\")\n",
    "\n",
    "    # Save final results to CSV in the results folder\n",
    "    final_csv_path = os.path.join(RESULTS_FOLDER, 'comparative_analysis_final.csv')\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    df_results.to_csv(final_csv_path, index=False)\n",
    "    print(f\"Final comparative analysis saved to '{final_csv_path}'.\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Download and extract the dataset\n",
    "    dataset_path = download_kaggle_dataset()\n",
    "\n",
    "    # Define the paths for train, validation, and test images\n",
    "    train_images_path = os.path.join(dataset_path, \"train/images\")\n",
    "  \n",
    "\n",
    "    # Run the object detection on each dataset\n",
    "    for dataset_name, dataset_path in [\n",
    "        (\"train\", train_images_path),\n",
    "     \n",
    "    ]:\n",
    "        print(f\"Starting object detection on {dataset_name} dataset...\")\n",
    "        run_object_detection(dataset_path, max_images=600, batch_size=10)\n",
    "\n",
    "    # Zip and download the results folder\n",
    "    !zip -r /content/object_detection_results.zip {RESULTS_FOLDER}\n",
    "    files.download('/content/object_detection_results.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
